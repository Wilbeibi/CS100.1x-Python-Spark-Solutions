{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wilbeibi's Pyspark Note**\n",
    "=======\n",
    "\n",
    "Document: [pyspark package](https://spark.apache.org/docs/latest/api/python/pyspark.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics: generate RDD and `map`\n",
    "    1. `sc.parallelize` to generate RDD, which typed as `<class 'pyspark.rdd.RDD'>`.\n",
    "    2. use RDD's `map` to operate each element in RDD, and `collect` to show the results.\n",
    "    3. list to RDD becomes rdd, generator (map function and so forth) to RDD becomes pipelinedRDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"wordsRDD's type: \", <class 'pyspark.rdd.RDD'>)\n",
      "(\"rangeRDD's type: \", <class 'pyspark.rdd.PipelinedRDD'>)\n",
      "['cats', 'elephants', 'rats', 'rats', 'cats'] <class 'pyspark.rdd.PipelinedRDD'>\n"
     ]
    }
   ],
   "source": [
    "wordsList = ['cat', 'elephant', 'rat', 'rat', 'cat']\n",
    "range_vals = xrange(200)\n",
    "\n",
    "wordsRDD = sc.parallelize(wordsList, 4)\n",
    "rangeRDD = sc.parallelize(range_vals, 20)\n",
    "# Print out the type of wordsRDD\n",
    "print (\"wordsRDD's type: \", type(wordsRDD))\n",
    "print (\"rangeRDD's type: \", type(rangeRDD))\n",
    "pluralLambdaRDD = wordsRDD.map(lambda w: w + 's')\n",
    "print pluralLambdaRDD.collect(), type(pluralLambdaRDD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `groupByKey() approach`\n",
    "groupByKey() transformation groups all the elements of the RDD with the same key into a single list in one of the partitions. When sort the RDD, we might need to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 1), ('elephant', 1), ('rat', 1), ('rat', 1), ('cat', 1)]\n",
      "rat: [1, 1]\n",
      "elephant: [1]\n",
      "cat: [1, 1]\n",
      "[('rat', 2), ('elephant', 1), ('cat', 2)]\n"
     ]
    }
   ],
   "source": [
    "# map word RDD into word:value pairs\n",
    "wordPairs = wordsRDD.map(lambda w:(w, 1))\n",
    "print wordPairs.collect()\n",
    "# group by word\n",
    "wordsGrouped = wordPairs.groupByKey()\n",
    "for key, value in wordsGrouped.collect():\n",
    "    print '{0}: {1}'.format(key, list(value))\n",
    "# count by words\n",
    "wordCountsGrouped = wordsGrouped.map(lambda (k, v): (k, sum(v)))\n",
    "print wordCountsGrouped.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `reduceByKey() approach`\n",
    "The `reduceByKey()` transformation gathers together pairs that have the same key and applies the function provided to two values at a time, iteratively reducing all of the values to a single value. `reduceByKey()` operates by applying the function first within each partition on a per-key basis and then across the partitions, allowing it to scale efficiently to large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rat', 2), ('elephant', 1), ('cat', 2)]\n"
     ]
    }
   ],
   "source": [
    "wordCounts = wordPairs.reduceByKey(lambda a, b: a+b)\n",
    "print wordCounts.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More operations on RDD\n",
    "+ `reduce()` works like python `reduce()`, the only differece is that it works on each element in RDD.\n",
    "+ `take(count)`, take first *count* elements. \n",
    "+ `filter(func)`, remove the elements which are `False` under *func*.\n",
    "+ `takeOrdered(count, func)`, take *count* elements by *func*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little bit regex\n",
    "+ Reference: [Python Regular Expressions: Essentional Materials](https://developers.google.com/edu/python/regular-expressions)\n",
    "+ `match = re.search(pat, str)` to search patterns\n",
    "+ `re.group(idx)` to show the `idx`th match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDD Creation\n",
    "+ `sc.textfile(logFile)` to convert each line of the file into an element in an RDD.\n",
    "+ `.cache()` operation in RDD Object will cache the data in memory. Needed if we want to seach the same results in further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
